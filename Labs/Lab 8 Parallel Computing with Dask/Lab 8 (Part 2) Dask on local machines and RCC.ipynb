{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Cluster Computing in Dask with RCC and AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Start of Using Dask Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we are going to learn about [**Dask**](https://dask.org/), a powerful and comprehensive cluster computing library in python. To install\n",
    "dask on your local machine, just run the following command:\n",
    "\n",
    "`python -m pip install \"dask[complete]\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to use the \"complete\" syntax here, which would automatically install all the core packages in dask. Besides, when running on the RCC system, where the python environment is managed by anaconda, it is highly recommended to create a virtual environment to hold dask. You can either run `conda install dask` or the command above to install dask in your conda environment.\n",
    "\n",
    "To use dask on a local single machine (e.g., your laptop), there is nothing else to install. You could simply run the following commands to start a local cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22177789ed834c898debfe38199ad5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>LocalCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()  # sceduler_port=1234\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a local cluster, the default number of processes started equals to the number of CPUs on the local machine. To adjust the number of workers (processes) in dask, you can use the scale method as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(4) #your number of processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask provides users with a convenient interface to monitor the usage and status of the workers in the cluster. To open the monitor, you just need to type `localhost:8787` after launching the cluster. 8787 is the default port number for the diagonastic server, you can also customize the port number by specifying the `dashboard_address` argument when setting up the cluster. More options to customize the local cluster configuration could be found [here](https://docs.dask.org/en/latest/setup/single-distributed.html).\n",
    "\n",
    "\n",
    "<img src=\"./dask_worker monitor.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the resources in the cluster, we need a scheduler to coordinate the operation and storage of the data, and this is why the client object in dask comes into being. The client object provides some functions similar to pool.map (map) and pool.apply (submit) in python multiprocessing, and also functions analogous to the scatter and gather methods in MPI4PY to handle large iterable objects and collect map results. Below it's a simple example of how to use these methods in dask, and all the data operation methods and data types, which we would mention in a moment, can all be used in the same way once the cluster is configured properly, no matter on a single machine or in a multi-node system (RCC) or a cloud computing platform (AWS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "def digit_sum(x):\n",
    "    string = str(x)\n",
    "    return sum([int(c) for c in string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# submit single jobs and get the result\n",
    "result_future = client.submit(digit_sum,1234)\n",
    "result_future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[62, 42, 40, 34, 57, 41, 40, 29, 57, 41]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit map jobs and get the result\n",
    "results_future = client.map(digit_sum, np.random.randint(1e+8, 1e+9, int(1e+4)))\n",
    "results = client.gather(results_future)\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can firstly scatter the data before mapping, this is useful when elements in the iterable are large. This generally works for python built-in iterables like list, tuple, set and dictionaries. For numpy arrays, please use client.map directly or dask.array to parallelize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <Future: finished, type: numpy.int64, key: 0>,\n",
       " 1: <Future: finished, type: numpy.int64, key: 1>,\n",
       " 2: <Future: finished, type: numpy.int64, key: 2>,\n",
       " 3: <Future: finished, type: numpy.int64, key: 3>,\n",
       " 4: <Future: finished, type: numpy.int64, key: 4>,\n",
       " 5: <Future: finished, type: numpy.int64, key: 5>,\n",
       " 6: <Future: finished, type: numpy.int64, key: 6>,\n",
       " 7: <Future: finished, type: numpy.int64, key: 7>,\n",
       " 8: <Future: finished, type: numpy.int64, key: 8>,\n",
       " 9: <Future: finished, type: numpy.int64, key: 9>,\n",
       " 10: <Future: finished, type: numpy.int64, key: 10>,\n",
       " 11: <Future: finished, type: numpy.int64, key: 11>,\n",
       " 12: <Future: finished, type: numpy.int64, key: 12>,\n",
       " 13: <Future: finished, type: numpy.int64, key: 13>,\n",
       " 14: <Future: finished, type: numpy.int64, key: 14>,\n",
       " 15: <Future: finished, type: numpy.int64, key: 15>,\n",
       " 16: <Future: finished, type: numpy.int64, key: 16>,\n",
       " 17: <Future: finished, type: numpy.int64, key: 17>,\n",
       " 18: <Future: finished, type: numpy.int64, key: 18>,\n",
       " 19: <Future: finished, type: numpy.int64, key: 19>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_future = client.scatter({x:y for x,y in enumerate(np.random.randint(1e+8,1e+9,20))})\n",
    "data_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31, 51, 43, 49, 41, 28, 39, 54, 42, 52]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_future = client.map(digit_sum, data_future.values())\n",
    "results = client.gather(results_future)\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this example, you see that dask would not directly send back the computation result but store them in the future objects instead. Future objects are stored in the shared memory for each processes. An advantage of this mechanism is that it can avoid unnecessary communications between processes, which cost extra time. This design is suitable for build up process pipelines, where we would have one or more intermediate results to pass through the whole process. That is to say, you can pass the intermediate data to another client.map function for further computation without the effort to manually send the data from local process to the shared memory.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask also provides interface for users to check the address, status, etc. of individual workers in code by defining the Nanny object. To check this, call cluster.workers and its affliated functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <Nanny: tcp://127.0.0.1:61531, threads: 2>,\n",
       " 1: <Nanny: tcp://127.0.0.1:61532, threads: 2>,\n",
       " 2: <Nanny: tcp://127.0.0.1:61529, threads: 2>,\n",
       " 3: <Nanny: tcp://127.0.0.1:61530, threads: 2>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restart (this means killing all currently running jobs and cleaning the memory) run the following, the restarted worker could have a different address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object Nanny.restart at 0x7ff8e50d5200>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_index = 0\n",
    "cluster.workers[worker_index].restart(timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    }
   ],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restart the cluster, use `client.restart()`. To shut down the local cluster, use `cluster.close()`. You do not have to manually shut down the client session since it would end as long as the python kernel is terminated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Dask in RCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following tutorial, we are going to use the same datasets in the spark session to get you familiar with using dask in a multi-node cluster computing environment, the RCC system. And we would still use the example of classifying the ratings of books to show the details of deploying dask in machine learning tasks.\n",
    "\n",
    "Ideally, we should be able to read the product review dataset from Amazon S3 using [dask.read_parquet](https://docs.dask.org/en/latest/dataframe-api.html?highlight=read_parquet#dask.dataframe.read_parquet). However, the RCC system is designed to block Internet connection on the compute nodes, which would be used as components of our Dask cluster. So we are unable to use Dask to parallelly read the external datasets from S3 on RCC. To make it work, we have manually downloaded the book review datasets to the directory of our class resource on RCC ('/project2/macs30123/'), and we can read the data \"locally\" on RCC now.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the nodes of RCC with dask, we need to install both dask and dask-jobqueue modules in our conda environment as follow. The [dask-jobqueue](https://jobqueue.dask.org/en/latest/) is used to deploy dask on common job queuing systems like PBS (used in SSD acropolis) and Slurm (used in RCC). It allows us to automatically generate sbatch scripts and directly submit them to the job manager system interactively in jupyter notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dask[complete]\n",
      "  Using cached https://files.pythonhosted.org/packages/04/94/b4012c61c09300f4413c58a522a6cc1a212dc4a7f6fe1ba98d67429c089d/dask-2.30.0-py3-none-any.whl\n",
      "Collecting dask-jobqueue\n",
      "  Using cached https://files.pythonhosted.org/packages/9a/66/02ef5356b167039753135d9eeac52fc8a4354a567e9525e53f2e0db681a7/dask_jobqueue-0.7.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask[complete]) (5.1)\n",
      "Requirement already satisfied, skipping upgrade: partd>=0.3.10; extra == \"complete\" in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask[complete]) (0.3.10)\n",
      "Requirement already satisfied, skipping upgrade: toolz>=0.8.2; extra == \"complete\" in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask[complete]) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.0; extra == \"complete\" in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask[complete]) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle>=0.2.2; extra == \"complete\" in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask[complete]) (0.8.0)\n",
      "Collecting distributed>=2.0; extra == \"complete\" (from dask[complete])\n",
      "  Using cached https://files.pythonhosted.org/packages/88/38/d9f0e31c15de18cb124d1ed33cf9c99c84f05f251ff6767e7573c217725b/distributed-2.30.1-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.23.0; extra == \"complete\" in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask[complete]) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: bokeh!=2.0.0,>=1.0.0; extra == \"complete\" in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask[complete]) (1.0.4)\n",
      "Collecting fsspec>=0.6.0; extra == \"complete\" (from dask[complete])\n",
      "  Using cached https://files.pythonhosted.org/packages/a5/8b/1df260f860f17cb08698170153ef7db672c497c1840dcc8613ce26a8a005/fsspec-0.8.4-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: locket in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from partd>=0.3.10; extra == \"complete\"->dask[complete]) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: zict>=0.1.3 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (0.1.4)\n",
      "Requirement already satisfied, skipping upgrade: sortedcontainers!=2.0.0,!=2.0.1 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (40.8.0)\n",
      "Requirement already satisfied, skipping upgrade: psutil>=5.0 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (5.6.1)\n",
      "Collecting tblib>=1.6.0 (from distributed>=2.0; extra == \"complete\"->dask[complete])\n",
      "  Using cached https://files.pythonhosted.org/packages/f8/cd/2fad4add11c8837e72f50a30e2bda30e67a10d70462f826b291443a55c7d/tblib-1.7.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: tornado>=5; python_version < \"3.8\" in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (6.0.2)\n",
      "Requirement already satisfied, skipping upgrade: msgpack>=0.6.0 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: click>=6.6 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from pandas>=0.23.0; extra == \"complete\"->dask[complete]) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from pandas>=0.23.0; extra == \"complete\"->dask[complete]) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.7 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from bokeh!=2.0.0,>=1.0.0; extra == \"complete\"->dask[complete]) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=16.8 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from bokeh!=2.0.0,>=1.0.0; extra == \"complete\"->dask[complete]) (19.0)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.0 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from bokeh!=2.0.0,>=1.0.0; extra == \"complete\"->dask[complete]) (5.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.2 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from bokeh!=2.0.0,>=1.0.0; extra == \"complete\"->dask[complete]) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: heapdict in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=2.0; extra == \"complete\"->dask[complete]) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh!=2.0.0,>=1.0.0; extra == \"complete\"->dask[complete]) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from packaging>=16.8->bokeh!=2.0.0,>=1.0.0; extra == \"complete\"->dask[complete]) (2.3.1)\n",
      "\u001b[31mdistributed 2.30.1 has requirement cloudpickle>=1.5.0, but you'll have cloudpickle 0.8.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tblib, distributed, fsspec, dask, dask-jobqueue\n",
      "\u001b[33m  The scripts dask-scheduler, dask-ssh and dask-worker are installed in '/home/linghuiwu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed dask-2.30.0 dask-jobqueue-0.7.1 distributed-2.30.1 fsspec-0.8.4 tblib-1.7.0\n"
     ]
    }
   ],
   "source": [
    "! pip install \"dask[complete]\" dask-jobqueue --upgrade --user #conda install dask-jobqueue -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct a cluster on RCC system, we use the SLURMCluster of the RCC system to define our sbatch scripts. The \"queue\" argument specifies the partition to which you would like to submit your jobs; the \"core\" argument specifies the number of CPUs you would like to use for each node (not the entire number of cpus); the \"memory\" argument defines the total memory allocation for a single node in the cluster, which is evenly distributed over all cpus; the \"process\" argument integrate cores into subgroups and for most pythonic jobs it is recommmended to make each process hold one cpu to avoid the [Global Interpreter Lock](https://realpython.com/python-gil/); the 'interface' argument is used to define the type of network interface linking different nodes, which in our case is the infiniband interconnect (ib0).       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linghuiwu/.local/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42197 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    }
   ],
   "source": [
    "import dask_jobqueue as jobq\n",
    "\n",
    "cluster = jobq.SLURMCluster(queue='broadwl',cores=10, memory='40GB',processes=10,  \n",
    "                            # `cores` = `processes` due to Python drawbacks\n",
    "                            walltime='01:00:00', interface='ib0', job_extra=['--account=macs30123']  \n",
    "                            # `interface` defines the type of communication b/w clusters\n",
    "                            #job_extra=['--output=dask_worker.out',\n",
    "                            #           '--error=dask_worker.err']\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the printed information (if none, use the default port number 8787), we can open the monitor at `localhost:[port-number]`. By default, there are no workers started at this moment, you can check the generated sbatch script, which is just like our sbatch files, before finally submitting the jobs to the queue system by using the scale methods, which would create the multi-node cluster needed by our parallel analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -p broadwl\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=10\n",
      "#SBATCH --mem=38G\n",
      "#SBATCH -t 01:00:00\n",
      "#SBATCH --account=macs30123\n",
      "\n",
      "/software/Anaconda3-2019.03-el7-x86_64/bin/python -m distributed.cli.dask_worker tcp://172.25.220.72:40306 --nthreads 1 --nprocs 10 --memory-limit 4.00GB --name name --nanny --death-timeout 60 --interface ib0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment of the client object is an important step to connect the dask backend to the cluster you just specified. Otherwise, they would just run on a local cluster (which is forbidden by RCC). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate 2 nodes to the cluster\n",
    "cluster.scale(jobs=2)\n",
    "\n",
    "# connect the local machine to the nodes\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.25.220.72:40306</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.25.220.72:42197/status' target='_blank'>http://172.25.220.72:42197/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.25.220.72:40306' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask was developed in coordination with other widely used python community projects like Numpy, Pandas, and Scikit-Learn. Like Spark, Dask provides users with parallelized arrays ([dask.array](https://docs.dask.org/en/latest/array.html)), dataframes ([dask.dataframe](https://docs.dask.org/en/latest/dataframe.html)) to store and process large dataset. It also includes a parallelized version of general python collection objects ([dask.bag](https://docs.dask.org/en/latest/bag.html)) for users to implement operations like map and filter. You would practice using these dask data types in courses on datacamp. For this section, we would primarily use the dask dataframes and arrays to finish the machine learning tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# load the book review data\n",
    "df = dd.read_csv('/project2/macs30123/AWS_book_reviews/*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The * symbol above is specially used in dask to read in multiple datasets in a parallel way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>15444933</td>\n",
       "      <td>R1WWG70WK9VUCH</td>\n",
       "      <td>1848192576</td>\n",
       "      <td>835940987</td>\n",
       "      <td>Standing Qigong for Health and Martial Arts - ...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Informative AND interesting!</td>\n",
       "      <td>After attending a few Qigong classes, I wanted...</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>20595117</td>\n",
       "      <td>R1EQ3POS0RIOD5</td>\n",
       "      <td>145162445X</td>\n",
       "      <td>574044348</td>\n",
       "      <td>A Universe from Nothing: Why There Is Somethin...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Between 'Nothing' and 'Nothing' somehow we are...</td>\n",
       "      <td>Krauss traces the remarkable transformation in...</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>52925878</td>\n",
       "      <td>R10SRJA4VVGUBD</td>\n",
       "      <td>055341805X</td>\n",
       "      <td>846590203</td>\n",
       "      <td>Hyacinth Girls: A Novel</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Mysteries upon mysteries</td>\n",
       "      <td>Rebecca, a dental hygienist, receives a call a...</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>40062567</td>\n",
       "      <td>RD3268X41GM7U</td>\n",
       "      <td>0425263908</td>\n",
       "      <td>119148606</td>\n",
       "      <td>Bared to You</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>\"RAW, STEAMY, HYPNOTIC!\"</td>\n",
       "      <td>\\\\\"BARED TO YOU\\\\\" is a sizzling, red-hot pass...</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>47221489</td>\n",
       "      <td>R3KGQL5X5BSJE1</td>\n",
       "      <td>1416556141</td>\n",
       "      <td>987400385</td>\n",
       "      <td>Healer: A Novel</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Well written story</td>\n",
       "      <td>Good characters and plot line. I spent a pleas...</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     15444933  R1WWG70WK9VUCH  1848192576       835940987   \n",
       "1          US     20595117  R1EQ3POS0RIOD5  145162445X       574044348   \n",
       "2          US     52925878  R10SRJA4VVGUBD  055341805X       846590203   \n",
       "3          US     40062567   RD3268X41GM7U  0425263908       119148606   \n",
       "4          US     47221489  R3KGQL5X5BSJE1  1416556141       987400385   \n",
       "\n",
       "                                       product_title  star_rating  \\\n",
       "0  Standing Qigong for Health and Martial Arts - ...            5   \n",
       "1  A Universe from Nothing: Why There Is Somethin...            4   \n",
       "2                            Hyacinth Girls: A Novel            4   \n",
       "3                                       Bared to You            5   \n",
       "4                                    Healer: A Novel            5   \n",
       "\n",
       "   helpful_votes  total_votes vine verified_purchase  \\\n",
       "0              9           10    N                 Y   \n",
       "1              4            7    N                 N   \n",
       "2              0            0    Y                 N   \n",
       "3              1            1    N                 N   \n",
       "4              0            0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                       Informative AND interesting!   \n",
       "1  Between 'Nothing' and 'Nothing' somehow we are...   \n",
       "2                           Mysteries upon mysteries   \n",
       "3                           \"RAW, STEAMY, HYPNOTIC!\"   \n",
       "4                                 Well written story   \n",
       "\n",
       "                                         review_body review_date  year  \n",
       "0  After attending a few Qigong classes, I wanted...  2015-05-02  2015  \n",
       "1  Krauss traces the remarkable transformation in...  2012-06-29  2012  \n",
       "2  Rebecca, a dental hygienist, receives a call a...  2015-05-02  2015  \n",
       "3  \\\\\"BARED TO YOU\\\\\" is a sizzling, red-hot pass...  2012-06-29  2012  \n",
       "4  Good characters and plot line. I spent a pleas...  2015-05-02  2015  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace          object\n",
       "customer_id           int64\n",
       "review_id            object\n",
       "product_id           object\n",
       "product_parent        int64\n",
       "product_title        object\n",
       "star_rating           int64\n",
       "helpful_votes         int64\n",
       "total_votes           int64\n",
       "vine                 object\n",
       "verified_purchase    object\n",
       "review_headline      object\n",
       "review_body          object\n",
       "review_date          object\n",
       "year                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Delayed('int-b4bf9fff-09b3-4e8b-9df0-31f4c0318290'), 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20726160"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.072616e+07</td>\n",
       "      <td>2.072616e+07</td>\n",
       "      <td>2.072616e+07</td>\n",
       "      <td>2.072616e+07</td>\n",
       "      <td>2.072616e+07</td>\n",
       "      <td>2.072616e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.287233e+07</td>\n",
       "      <td>5.012232e+08</td>\n",
       "      <td>4.340540e+00</td>\n",
       "      <td>3.836475e+00</td>\n",
       "      <td>5.332147e+00</td>\n",
       "      <td>2.010451e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.545060e+07</td>\n",
       "      <td>2.878609e+08</td>\n",
       "      <td>1.125604e+00</td>\n",
       "      <td>2.240867e+01</td>\n",
       "      <td>2.581018e+01</td>\n",
       "      <td>4.506381e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.002400e+04</td>\n",
       "      <td>5.760000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.995000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.888019e+07</td>\n",
       "      <td>2.623204e+08</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.010000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.314521e+07</td>\n",
       "      <td>5.120222e+08</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.013000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.259045e+07</td>\n",
       "      <td>7.577690e+08</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.014000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.309659e+07</td>\n",
       "      <td>9.999999e+08</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2.755000e+04</td>\n",
       "      <td>2.872700e+04</td>\n",
       "      <td>2.015000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        customer_id  product_parent   star_rating  helpful_votes  \\\n",
       "count  2.072616e+07    2.072616e+07  2.072616e+07   2.072616e+07   \n",
       "mean   3.287233e+07    5.012232e+08  4.340540e+00   3.836475e+00   \n",
       "std    1.545060e+07    2.878609e+08  1.125604e+00   2.240867e+01   \n",
       "min    1.002400e+04    5.760000e+02  1.000000e+00   0.000000e+00   \n",
       "25%    2.888019e+07    2.623204e+08  4.000000e+00   0.000000e+00   \n",
       "50%    4.314521e+07    5.120222e+08  5.000000e+00   1.000000e+00   \n",
       "75%    5.259045e+07    7.577690e+08  5.000000e+00   7.000000e+00   \n",
       "max    5.309659e+07    9.999999e+08  5.000000e+00   2.755000e+04   \n",
       "\n",
       "        total_votes          year  \n",
       "count  2.072616e+07  2.072616e+07  \n",
       "mean   5.332147e+00  2.010451e+03  \n",
       "std    2.581018e+01  4.506381e+00  \n",
       "min    0.000000e+00  1.995000e+03  \n",
       "25%    1.000000e+00  2.010000e+03  \n",
       "50%    2.000000e+00  2.013000e+03  \n",
       "75%    9.000000e+00  2.014000e+03  \n",
       "max    2.872700e+04  2.015000e+03  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above data exploration, we could see that the dask dataset has many methods that are analogous to the functions in [pandas](https://pandas.pydata.org/docs/reference/index.html), so it would be very easy-to-use if you are already familiar with pandas. One major difference is the use of delay mechanism in dask dataframes, which is revealed by the compute() function. This means that dataframe operations would not be executed unless the compute method is called, and this would trigger all previously called related operations to be performed like a pipeline.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to perform the preprocessing for the book review dataset to obtain our features and labels for the machine learning task. Based on our intuition, id_like attributes are not likely to provide much useful information. Other attributes like total_votes and helpful_votes might contain more useful information about the ratings of books. We can make a mean calculation based on the groupby results to check our speculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marketplace</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>4.196011e+07</td>\n",
       "      <td>5.047194e+08</td>\n",
       "      <td>4.358941</td>\n",
       "      <td>2.360758</td>\n",
       "      <td>3.647635</td>\n",
       "      <td>2005.886768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>3.075995e+07</td>\n",
       "      <td>5.214875e+08</td>\n",
       "      <td>4.308173</td>\n",
       "      <td>2.785668</td>\n",
       "      <td>3.946417</td>\n",
       "      <td>2011.635635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JP</th>\n",
       "      <td>3.667752e+07</td>\n",
       "      <td>5.157488e+08</td>\n",
       "      <td>4.452929</td>\n",
       "      <td>6.054778</td>\n",
       "      <td>8.073038</td>\n",
       "      <td>2009.791874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>3.263059e+07</td>\n",
       "      <td>5.065183e+08</td>\n",
       "      <td>4.363765</td>\n",
       "      <td>2.979392</td>\n",
       "      <td>4.290699</td>\n",
       "      <td>2012.018752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>3.284676e+07</td>\n",
       "      <td>5.011147e+08</td>\n",
       "      <td>4.340153</td>\n",
       "      <td>3.851688</td>\n",
       "      <td>5.350379</td>\n",
       "      <td>2010.444432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              customer_id  product_parent  star_rating  helpful_votes  \\\n",
       "marketplace                                                             \n",
       "DE           4.196011e+07    5.047194e+08     4.358941       2.360758   \n",
       "FR           3.075995e+07    5.214875e+08     4.308173       2.785668   \n",
       "JP           3.667752e+07    5.157488e+08     4.452929       6.054778   \n",
       "UK           3.263059e+07    5.065183e+08     4.363765       2.979392   \n",
       "US           3.284676e+07    5.011147e+08     4.340153       3.851688   \n",
       "\n",
       "             total_votes         year  \n",
       "marketplace                            \n",
       "DE              3.647635  2005.886768  \n",
       "FR              3.946417  2011.635635  \n",
       "JP              8.073038  2009.791874  \n",
       "UK              4.290699  2012.018752  \n",
       "US              5.350379  2010.444432  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a groupby operation\n",
    "df.groupby(by='marketplace').mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we manually encoded the categorical of vine and verified_purchase. You can also do this in dask with the [OrdinalEncoder](https://ml.dask.org/modules/generated/dask_ml.preprocessing.OrdinalEncoder.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding some coded features\n",
    "df['vine_code'] = df['vine'].apply(lambda x:1 if x=='Y' else 0, meta=('vine', 'int64'))\n",
    "df['verified_purchase_code'] = df['verified_purchase'].apply(lambda x:1 if x=='Y' else 0, meta=('vine', 'int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vine_code</th>\n",
       "      <th>verified_purchase_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vine_code  verified_purchase_code\n",
       "0          0                       1\n",
       "1          0                       0\n",
       "2          1                       0\n",
       "3          0                       0\n",
       "4          0                       1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['vine_code','verified_purchase_code']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>year</th>\n",
       "      <th>vine_code</th>\n",
       "      <th>verified_purchase_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.447849e+07</td>\n",
       "      <td>5.016755e+08</td>\n",
       "      <td>9.876988</td>\n",
       "      <td>20.341088</td>\n",
       "      <td>2009.393735</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.354239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.533688e+07</td>\n",
       "      <td>5.006462e+08</td>\n",
       "      <td>6.476555</td>\n",
       "      <td>10.455063</td>\n",
       "      <td>2009.584428</td>\n",
       "      <td>0.019910</td>\n",
       "      <td>0.427630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.446525e+07</td>\n",
       "      <td>5.004053e+08</td>\n",
       "      <td>4.549026</td>\n",
       "      <td>6.554343</td>\n",
       "      <td>2010.105793</td>\n",
       "      <td>0.033166</td>\n",
       "      <td>0.470260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.394212e+07</td>\n",
       "      <td>5.005828e+08</td>\n",
       "      <td>3.130165</td>\n",
       "      <td>3.934887</td>\n",
       "      <td>2010.061811</td>\n",
       "      <td>0.029201</td>\n",
       "      <td>0.460472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.212843e+07</td>\n",
       "      <td>5.014813e+08</td>\n",
       "      <td>3.281001</td>\n",
       "      <td>4.011696</td>\n",
       "      <td>2010.731501</td>\n",
       "      <td>0.007675</td>\n",
       "      <td>0.546666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              customer_id  product_parent  helpful_votes  total_votes  \\\n",
       "star_rating                                                             \n",
       "1            3.447849e+07    5.016755e+08       9.876988    20.341088   \n",
       "2            3.533688e+07    5.006462e+08       6.476555    10.455063   \n",
       "3            3.446525e+07    5.004053e+08       4.549026     6.554343   \n",
       "4            3.394212e+07    5.005828e+08       3.130165     3.934887   \n",
       "5            3.212843e+07    5.014813e+08       3.281001     4.011696   \n",
       "\n",
       "                    year  vine_code  verified_purchase_code  \n",
       "star_rating                                                  \n",
       "1            2009.393735   0.003899                0.354239  \n",
       "2            2009.584428   0.019910                0.427630  \n",
       "3            2010.105793   0.033166                0.470260  \n",
       "4            2010.061811   0.029201                0.460472  \n",
       "5            2010.731501   0.007675                0.546666  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a groupby operation\n",
    "df.groupby(by='star_rating').mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, it seems that our guesses are likely to be correct. For these numerical features, helpful_votes, total_votes, vine_code and verified_purchase_code would be included in our machine learning task.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All available feature engineering tools in dask are covered in [dask_ml](https://ml.dask.org/index.html), which we need to install first. To precess the text in dask, you can visit the [vectorizers](https://ml.dask.org/modules/generated/dask_ml.preprocessing.OrdinalEncoder.html) for more information. Noticing that the result of text processing are dask arrays with scipy sparse matrix internally. If you want to check the values in them, you need to use the toarray() or todense() methods.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dask_ml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/b0/3d4b11fd2468dd098ab6ef2a5a094192daddb812c11da948b9f318a46073/dask_ml-1.7.0-py3-none-any.whl (141kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 8.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask_ml) (19.0)\n",
      "Requirement already satisfied, skipping upgrade: dask[array,dataframe]>=2.4.0 in /home/linghuiwu/.local/lib/python3.7/site-packages (from dask_ml) (2.30.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask_ml) (1.4.1)\n",
      "Collecting dask-glm>=0.2.0 (from dask_ml)\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/ee/36c6e0e7b51e08406e5c3bb036f35adb77bd0a89335437b2e6f03c948f1a/dask_glm-0.2.0-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.17.3 (from dask_ml)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/bb/87d668b353848b93baab0a64cddf6408c40717f099539668c3d26fe39f7e/numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 14.5MB 1.8MB/s eta 0:00:01   17% |█████▌                          | 2.5MB 44.0MB/s eta 0:00:01    47% |███████████████▎                | 6.9MB 40.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn>=0.23 (from dask_ml)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.8MB 2.7MB/s eta 0:00:01    66% |█████████████████████▏          | 4.5MB 49.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: multipledispatch>=0.4.9 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask_ml) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: distributed>=2.4.0 in /home/linghuiwu/.local/lib/python3.7/site-packages (from dask_ml) (2.30.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.24.2 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask_ml) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: numba in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask_ml) (0.47.0+0.g4eb9cf875.dirty)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from packaging->dask_ml) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from packaging->dask_ml) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (5.1)\n",
      "Requirement already satisfied, skipping upgrade: toolz>=0.8.2; extra == \"array\" in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: fsspec>=0.6.0; extra == \"dataframe\" in /home/linghuiwu/.local/lib/python3.7/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: partd>=0.3.10; extra == \"dataframe\" in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.3.10)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle>=0.2.2 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from dask-glm>=0.2.0->dask_ml) (0.8.0)\n",
      "Collecting joblib>=0.11 (from scikit-learn>=0.23->dask_ml)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 8.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn>=0.23->dask_ml)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: tornado>=5; python_version < \"3.8\" in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.4.0->dask_ml) (6.0.2)\n",
      "Requirement already satisfied, skipping upgrade: zict>=0.1.3 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.4.0->dask_ml) (0.1.4)\n",
      "Requirement already satisfied, skipping upgrade: tblib>=1.6.0 in /home/linghuiwu/.local/lib/python3.7/site-packages (from distributed>=2.4.0->dask_ml) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.4.0->dask_ml) (40.8.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=6.6 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.4.0->dask_ml) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: sortedcontainers!=2.0.0,!=2.0.1 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.4.0->dask_ml) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: msgpack>=0.6.0 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.4.0->dask_ml) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: psutil>=5.0 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from distributed>=2.4.0->dask_ml) (5.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from pandas>=0.24.2->dask_ml) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from pandas>=0.24.2->dask_ml) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: llvmlite>=0.31.0dev0 in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from numba->dask_ml) (0.31.0)\n",
      "Requirement already satisfied, skipping upgrade: locket in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from partd>=0.3.10; extra == \"dataframe\"->dask[array,dataframe]>=2.4.0->dask_ml) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: heapdict in /software/Anaconda3-2019.03-el7-x86_64/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=2.4.0->dask_ml) (1.0.0)\n",
      "\u001b[31mtensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\n",
      "\u001b[31mnetcdf4 1.5.3 requires cftime, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.13.1 has requirement tensorflow-estimator<1.14.0rc0,>=1.13.0, but you'll have tensorflow-estimator 2.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mjqdatasdk 1.8.1 has requirement pandas<=0.25.3,>=0.16.2, but you'll have pandas 1.0.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, joblib, threadpoolctl, scikit-learn, dask-glm, dask-ml\n",
      "\u001b[33m  The scripts f2py, f2py3 and f2py3.7 are installed in '/home/linghuiwu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed dask-glm-0.2.0 dask-ml-1.7.0 joblib-0.17.0 numpy-1.19.4 scikit-learn-0.23.2 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dask_ml --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with missing values \n",
    "df[['review_body','review_headline']]=df[['review_body','review_headline']].fillna(value='empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "\n",
       "    <tr><th> Shape </th><td> (20726160, 64) </td> <td> (129341, 64) </td></tr>\n",
       "    <tr><th> Count </th><td> 3920 Tasks </td><td> 280 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> scipy.csr_matrix </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"25\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"19\" x2=\"25\" y2=\"19\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"25\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"25\" y2=\"37\" />\n",
       "  <line x1=\"0\" y1=\"44\" x2=\"25\" y2=\"44\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"25\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"25\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"63\" x2=\"25\" y2=\"63\" />\n",
       "  <line x1=\"0\" y1=\"69\" x2=\"25\" y2=\"69\" />\n",
       "  <line x1=\"0\" y1=\"76\" x2=\"25\" y2=\"76\" />\n",
       "  <line x1=\"0\" y1=\"81\" x2=\"25\" y2=\"81\" />\n",
       "  <line x1=\"0\" y1=\"89\" x2=\"25\" y2=\"89\" />\n",
       "  <line x1=\"0\" y1=\"94\" x2=\"25\" y2=\"94\" />\n",
       "  <line x1=\"0\" y1=\"101\" x2=\"25\" y2=\"101\" />\n",
       "  <line x1=\"0\" y1=\"107\" x2=\"25\" y2=\"107\" />\n",
       "  <line x1=\"0\" y1=\"114\" x2=\"25\" y2=\"114\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >64</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">20726160</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<_transformer, shape=(20726160, 64), dtype=float64, chunksize=(129341, 64), chunktype=scipy.csr_matrix>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml import feature_extraction\n",
    "\n",
    "vect = feature_extraction.text.HashingVectorizer(stop_words='english', n_features=64)\n",
    "text_sparse_array = vect.fit_transform(df['review_body'])\n",
    "text_sparse_array.compute_chunk_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>year</th>\n",
       "      <th>vine_code</th>\n",
       "      <th>verified_purchase_code</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>15444933</td>\n",
       "      <td>R1WWG70WK9VUCH</td>\n",
       "      <td>1848192576</td>\n",
       "      <td>835940987</td>\n",
       "      <td>Standing Qigong for Health and Martial Arts - ...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Informative AND interesting!</td>\n",
       "      <td>After attending a few Qigong classes, I wanted...</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>20595117</td>\n",
       "      <td>R1EQ3POS0RIOD5</td>\n",
       "      <td>145162445X</td>\n",
       "      <td>574044348</td>\n",
       "      <td>A Universe from Nothing: Why There Is Somethin...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Between 'Nothing' and 'Nothing' somehow we are...</td>\n",
       "      <td>Krauss traces the remarkable transformation in...</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>52925878</td>\n",
       "      <td>R10SRJA4VVGUBD</td>\n",
       "      <td>055341805X</td>\n",
       "      <td>846590203</td>\n",
       "      <td>Hyacinth Girls: A Novel</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Mysteries upon mysteries</td>\n",
       "      <td>Rebecca, a dental hygienist, receives a call a...</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>40062567</td>\n",
       "      <td>RD3268X41GM7U</td>\n",
       "      <td>0425263908</td>\n",
       "      <td>119148606</td>\n",
       "      <td>Bared to You</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>\"RAW, STEAMY, HYPNOTIC!\"</td>\n",
       "      <td>\\\\\"BARED TO YOU\\\\\" is a sizzling, red-hot pass...</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>47221489</td>\n",
       "      <td>R3KGQL5X5BSJE1</td>\n",
       "      <td>1416556141</td>\n",
       "      <td>987400385</td>\n",
       "      <td>Healer: A Novel</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Well written story</td>\n",
       "      <td>Good characters and plot line. I spent a pleas...</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     15444933  R1WWG70WK9VUCH  1848192576       835940987   \n",
       "1          US     20595117  R1EQ3POS0RIOD5  145162445X       574044348   \n",
       "2          US     52925878  R10SRJA4VVGUBD  055341805X       846590203   \n",
       "3          US     40062567   RD3268X41GM7U  0425263908       119148606   \n",
       "4          US     47221489  R3KGQL5X5BSJE1  1416556141       987400385   \n",
       "\n",
       "                                       product_title  star_rating  \\\n",
       "0  Standing Qigong for Health and Martial Arts - ...            5   \n",
       "1  A Universe from Nothing: Why There Is Somethin...            4   \n",
       "2                            Hyacinth Girls: A Novel            4   \n",
       "3                                       Bared to You            5   \n",
       "4                                    Healer: A Novel            5   \n",
       "\n",
       "   helpful_votes  total_votes vine verified_purchase  \\\n",
       "0              9           10    N                 Y   \n",
       "1              4            7    N                 N   \n",
       "2              0            0    Y                 N   \n",
       "3              1            1    N                 N   \n",
       "4              0            0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                       Informative AND interesting!   \n",
       "1  Between 'Nothing' and 'Nothing' somehow we are...   \n",
       "2                           Mysteries upon mysteries   \n",
       "3                           \"RAW, STEAMY, HYPNOTIC!\"   \n",
       "4                                 Well written story   \n",
       "\n",
       "                                         review_body review_date  year  \\\n",
       "0  After attending a few Qigong classes, I wanted...  2015-05-02  2015   \n",
       "1  Krauss traces the remarkable transformation in...  2012-06-29  2012   \n",
       "2  Rebecca, a dental hygienist, receives a call a...  2015-05-02  2015   \n",
       "3  \\\\\"BARED TO YOU\\\\\" is a sizzling, red-hot pass...  2012-06-29  2012   \n",
       "4  Good characters and plot line. I spent a pleas...  2015-05-02  2015   \n",
       "\n",
       "   vine_code  verified_purchase_code  label  \n",
       "0          0                       1      1  \n",
       "1          0                       0      1  \n",
       "2          1                       0      1  \n",
       "3          0                       0      1  \n",
       "4          0                       1      1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['star_rating'].apply(lambda x:1 if x > 3 else 0, meta=('star_rating', 'int64'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0     3517710\n",
       "1    17208450\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count().compute()['star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick up some features we think of useful as features\n",
    "num_feature_df = df[['helpful_votes','total_votes','vine_code','verified_purchase_code']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to do some scaling here to decrease the effect of different scales for difffernt attributes. For different scale methods, you can see [here](https://ml.dask.org/modules/api.html#module-dask_ml.preprocessing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine_code</th>\n",
       "      <th>verified_purchase_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   helpful_votes  total_votes  vine_code  verified_purchase_code\n",
       "0       0.000327     0.000348        0.0                     1.0\n",
       "1       0.000145     0.000244        0.0                     0.0\n",
       "2       0.000000     0.000000        1.0                     0.0\n",
       "3       0.000036     0.000035        0.0                     0.0\n",
       "4       0.000000     0.000000        0.0                     1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "num_feature_df = scaler.fit_transform(num_feature_df)\n",
    "num_feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array\n",
    "label_array = df['label'].to_dask_array().compute_chunk_sizes()\n",
    "num_feature_array = num_feature_df.to_dask_array().compute_chunk_sizes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth mentioning the usage of compute_chunk_sizes(), this function computes and memorizes the original size and chunk size of the datasets which is useful for deciding how many samples we need for train and test sets. Previously, the total sample size of feature and label arrays are not known because they are distributed over the cluster nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally come to the train-test section. Actually, dask hoes not developed most of their machine learning models. They developed parallel interface for a resourceful machine learning package [scikit-learn](https://scikit-learn.org/stable/). So the way we run machine learning methods in dask is quite similar to using scikit-learn.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the numerical features\n",
    "from dask_ml.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(num_feature_array, \n",
    "                                                  label_array,\n",
    "                                                  train_size=0.7,test_size=0.3,\n",
    "                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 464.26 MB </td> <td> 2.90 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (14508174, 4) </td> <td> (90538, 4) </td></tr>\n",
       "    <tr><th> Count </th><td> 2240 Tasks </td><td> 280 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"25\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"19\" x2=\"25\" y2=\"19\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"25\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"25\" y2=\"37\" />\n",
       "  <line x1=\"0\" y1=\"44\" x2=\"25\" y2=\"44\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"25\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"25\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"63\" x2=\"25\" y2=\"63\" />\n",
       "  <line x1=\"0\" y1=\"69\" x2=\"25\" y2=\"69\" />\n",
       "  <line x1=\"0\" y1=\"76\" x2=\"25\" y2=\"76\" />\n",
       "  <line x1=\"0\" y1=\"81\" x2=\"25\" y2=\"81\" />\n",
       "  <line x1=\"0\" y1=\"89\" x2=\"25\" y2=\"89\" />\n",
       "  <line x1=\"0\" y1=\"94\" x2=\"25\" y2=\"94\" />\n",
       "  <line x1=\"0\" y1=\"101\" x2=\"25\" y2=\"101\" />\n",
       "  <line x1=\"0\" y1=\"107\" x2=\"25\" y2=\"107\" />\n",
       "  <line x1=\"0\" y1=\"114\" x2=\"25\" y2=\"114\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >4</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">14508174</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<concatenate, shape=(14508174, 4), dtype=float64, chunksize=(90538, 4), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 49.74 MB </td> <td> 310.42 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (6217985,) </td> <td> (38803,) </td></tr>\n",
       "    <tr><th> Count </th><td> 2240 Tasks </td><td> 280 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> int64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"6\" y1=\"0\" x2=\"6\" y2=\"25\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"25\" />\n",
       "  <line x1=\"19\" y1=\"0\" x2=\"19\" y2=\"25\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"25\" />\n",
       "  <line x1=\"31\" y1=\"0\" x2=\"31\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"44\" y1=\"0\" x2=\"44\" y2=\"25\" />\n",
       "  <line x1=\"50\" y1=\"0\" x2=\"50\" y2=\"25\" />\n",
       "  <line x1=\"56\" y1=\"0\" x2=\"56\" y2=\"25\" />\n",
       "  <line x1=\"63\" y1=\"0\" x2=\"63\" y2=\"25\" />\n",
       "  <line x1=\"69\" y1=\"0\" x2=\"69\" y2=\"25\" />\n",
       "  <line x1=\"76\" y1=\"0\" x2=\"76\" y2=\"25\" />\n",
       "  <line x1=\"81\" y1=\"0\" x2=\"81\" y2=\"25\" />\n",
       "  <line x1=\"89\" y1=\"0\" x2=\"89\" y2=\"25\" />\n",
       "  <line x1=\"94\" y1=\"0\" x2=\"94\" y2=\"25\" />\n",
       "  <line x1=\"101\" y1=\"0\" x2=\"101\" y2=\"25\" />\n",
       "  <line x1=\"107\" y1=\"0\" x2=\"107\" y2=\"25\" />\n",
       "  <line x1=\"114\" y1=\"0\" x2=\"114\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >6217985</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<concatenate, shape=(6217985,), dtype=int64, chunksize=(38803,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using class weights to mitigate data imbalance\n",
    "class_counts = df.groupby('label').count().compute()['star_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask allows you to use multiple models from sklearn, and here we use the SGD classifier to perform the machine learning task. As you can see from the code, we implement cross validation and hyperparameter searching in the model, which is the best part in machine learning tasks to be parallelized. The IncrementalSearchCV we used here is designed for models that have [partial_fit](https://ml.dask.org/modules/generated/dask_ml.wrappers.Incremental.html#) functions, like the SGDClassifier. These incremental learners can train on batches of data. This fits well with Dask’s blocked data structures. Besides, the use of hyper-parameter optimizer is also related to the constraint posed by memory and the increased complexity with more parameters. For details about how to choose this the optimizer, you could view [here](https://ml.dask.org/hyper-parameter-search.html?highlight=memory#scaling-hyperparameter-searches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linghuiwu/.local/lib/python3.7/site-packages/dask_ml/model_selection/_incremental.py:999: FutureWarning: decay_rate has been deprecated since Dask-ML v1.4.0.\n",
      "\n",
      "    * Use InverseDecaySearchCV to use `decay_rate`\n",
      "    * Specify decay_rate=None\n",
      "\n",
      "\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncrementalSearchCV(estimator=SGDClassifier(class_weight={0: 1,\n",
       "                                                          1: 0.20441759716883276}),\n",
       "                    parameters={'alpha': array([1.00000000e-04, 1.00926219e-04, 1.01861017e-04, 1.02804473e-04,\n",
       "       1.03756668e-04, 1.04717682e-04, 1.05687597e-04, 1.06666496e-04,\n",
       "       1.07654461e-04, 1.08651577e-04, 1.09657929e-04, 1.10673602e-04,\n",
       "       1.11698682e-04, 1.12733256e-04, 1.13777413e-04, 1.14831241e-...\n",
       "       8.39312950e-01, 8.47086827e-01, 8.54932707e-01, 8.62851257e-01,\n",
       "       8.70843150e-01, 8.78909065e-01, 8.87049689e-01, 8.95265713e-01,\n",
       "       9.03557835e-01, 9.11926760e-01, 9.20373200e-01, 9.28897872e-01,\n",
       "       9.37501502e-01, 9.46184819e-01, 9.54948564e-01, 9.63793480e-01,\n",
       "       9.72720319e-01, 9.81729841e-01, 9.90822810e-01, 1.00000000e+00]),\n",
       "                                'average': [True, False],\n",
       "                                'loss': ['hinge', 'log', 'modified_huber',\n",
       "                                         'squared_hinge']})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml.model_selection import IncrementalSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "#import joblib\n",
    "\n",
    "clf = SGDClassifier(class_weight={0:1,1:class_counts[0]/class_counts[1]})\n",
    "params = {'alpha': np.logspace(-4, 0, num=1000),\n",
    "          'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge'],\n",
    "          'average': [True, False]}\n",
    "#clf.fit(X_train, y_train)\n",
    "#clf = Incremental(est, scoring='accuracy')\n",
    "search = IncrementalSearchCV(clf, params)\n",
    "search.fit(X_train, y_train, classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.03392583382740992,\n",
       "              class_weight={0: 1, 1: 0.20441759716883276})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the best parameter\n",
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289739592355216"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train accuracy\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8302773326085541"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the test accuracy\n",
    "search.best_estimator_.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "plot_confusion_matrix(search.best_estimator_, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This primitive model suffers a lot from data imbalance even after we specified weights. So you may need to find some other ways to reduce this negative effect in your assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all the features\n",
    "from dask_ml.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(text_sparse_array,\n",
    "                                                  label_array,\n",
    "                                                  train_size=0.7,test_size=0.3,\n",
    "                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 7.43 GB </td> <td> 46.36 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (14508174, 64) </td> <td> (90538, 64) </td></tr>\n",
       "    <tr><th> Count </th><td> 2240 Tasks </td><td> 280 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"25\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"19\" x2=\"25\" y2=\"19\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"25\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"25\" y2=\"37\" />\n",
       "  <line x1=\"0\" y1=\"44\" x2=\"25\" y2=\"44\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"25\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"25\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"63\" x2=\"25\" y2=\"63\" />\n",
       "  <line x1=\"0\" y1=\"69\" x2=\"25\" y2=\"69\" />\n",
       "  <line x1=\"0\" y1=\"76\" x2=\"25\" y2=\"76\" />\n",
       "  <line x1=\"0\" y1=\"81\" x2=\"25\" y2=\"81\" />\n",
       "  <line x1=\"0\" y1=\"89\" x2=\"25\" y2=\"89\" />\n",
       "  <line x1=\"0\" y1=\"94\" x2=\"25\" y2=\"94\" />\n",
       "  <line x1=\"0\" y1=\"101\" x2=\"25\" y2=\"101\" />\n",
       "  <line x1=\"0\" y1=\"107\" x2=\"25\" y2=\"107\" />\n",
       "  <line x1=\"0\" y1=\"114\" x2=\"25\" y2=\"114\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >64</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">14508174</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<concatenate, shape=(14508174, 64), dtype=float64, chunksize=(90538, 64), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Incremental(estimator=SGDClassifier(class_weight={0: 1,\n",
       "                                                  1: 0.20441759716883276}),\n",
       "            scoring='accuracy')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import dask_ml\n",
    "\n",
    "sgd = SGDClassifier(class_weight={0:1, 1:class_counts[0] / class_counts[1]})\n",
    "clf = dask_ml.wrappers.Incremental(\n",
    "    sgd, scoring='accuracy',\n",
    ")\n",
    "clf.fit(X_train,y_train, classes=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5906311159488438"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5906009744314276"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_array = X_test.compute().toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "plot_confusion_matrix(clf.estimator_, X_test_array, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result here, we see that both of the two models have some drawbacks. Using the numerical (including categorical) features yield a result of high bias while using the pure text-based (review-body) features makes the overall accuracy very low. What about use both of these features? It's your turn to try! However, I have to notify you that the sparse matrix generated by the text vectors do not function well with many models, as it has some structural differences with ordinary arrays (like shape). So you might need to think about a feasible way to transfer the text vectors to normal numpy arrays and reload it to dask (This sounds somewhat inefficient, if you have better ideas, please let us know~).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
